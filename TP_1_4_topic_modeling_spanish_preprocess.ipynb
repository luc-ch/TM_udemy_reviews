{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zbQv8f_tjWq4"
   },
   "source": [
    "In this article we will implementing topics model with gensim, topic models are \n",
    "probabilistic models which contains information about topics in the\n",
    "text. A topic is like theme, or in other words underlying ideas represented in text. \n",
    "For example, we are working with a corpus of **spanish newspaper articles**,\n",
    "possible topics would be  politics, conflicts, elections and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V0UBlkyp_gme"
   },
   "source": [
    "#### Load the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ui5Uo0hn_eGm"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim\n",
    "import numpy as np\n",
    "from gensim.models import CoherenceModel, LdaModel, LsiModel, HdpModel\n",
    "from gensim.corpora import Dictionary\n",
    "# from gensim.models.wrappers import LdaMallet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SBS3r7AFAEtg"
   },
   "source": [
    "### Connect to drive to get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 162
    },
    "colab_type": "code",
    "id": "550zxhdVCl6y",
    "outputId": "8e6c130a-bccd-47e4-c00d-d8c22ff325ce"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>course</th>\n",
       "      <th>rating</th>\n",
       "      <th>comment</th>\n",
       "      <th>user</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51893</th>\n",
       "      <td>61574892</td>\n",
       "      <td>922644</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Para mi fue una fuente continua de información útil para aplicar, todos los mensajes son claros y precisos, encontré mucho para mejorar, entendí porque pierdo el interés en la mayoría de las presentaciones empresariales y que no debo ser el único. Totalmente para recomendar!!!\\n\\nPD: Algunos temas quizás sea bueno dividirlos, especialmente aquellos que durán más de 5 a 7 minutos.</td>\n",
       "      <td>Mariano Buñirigo</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70521</th>\n",
       "      <td>2606180</td>\n",
       "      <td>166170</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Da uma visão clara sobre o negocíos.</td>\n",
       "      <td>Roseana Santos de Freitas</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63186</th>\n",
       "      <td>35583622</td>\n",
       "      <td>749262</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Me ayudo a entender mucho algunas cosas que no sabia</td>\n",
       "      <td>Lorenzo Santiago Saul Arias Villegas</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77793</th>\n",
       "      <td>80370794</td>\n",
       "      <td>3314342</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Es un excelente curso, enseñas muy bien, gracias.</td>\n",
       "      <td>Kevin</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67355</th>\n",
       "      <td>80597074</td>\n",
       "      <td>1254714</td>\n",
       "      <td>4.0</td>\n",
       "      <td>fue buena pero demaciada explicacion un poko confusa pero necesaria</td>\n",
       "      <td>Alexis Fernando Espinoza Arce</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25409</th>\n",
       "      <td>65666142</td>\n",
       "      <td>3332670</td>\n",
       "      <td>5.0</td>\n",
       "      <td>me parecio muy bueno,pero me hubiera gustado que explicara los tonos para cada tipo d piel y cuando se tiene q hacer de nuevo o como saber si es al ano o algo asi</td>\n",
       "      <td>Elizabeth Aranda</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20194</th>\n",
       "      <td>60168386</td>\n",
       "      <td>2096652</td>\n",
       "      <td>5.0</td>\n",
       "      <td>muy buen curso a persa que se aborda no profundiza me paresio muy buen</td>\n",
       "      <td>Paulina Guadalupe López Espinoza</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6207</th>\n",
       "      <td>72222592</td>\n",
       "      <td>1133110</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Perfecto, el profesor es muy atento y ayuda con lo que puede. se aprende bastante, mucho mejor que otros cursos del mismo nivel.</td>\n",
       "      <td>Jose Manuel Lopez Gomez</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6887</th>\n",
       "      <td>57956543</td>\n",
       "      <td>1363082</td>\n",
       "      <td>5.0</td>\n",
       "      <td>MUY BUENO, EXCELENTE!!!!!!</td>\n",
       "      <td>Robeff Angel Darío</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43301</th>\n",
       "      <td>68937214</td>\n",
       "      <td>2426324</td>\n",
       "      <td>5.0</td>\n",
       "      <td>fue muy buena eleccion avian cosas que me costaban y las entendi</td>\n",
       "      <td>Soledad Garro</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id   course  rating                                                                                                                                                                                                                                                                                                                                                                                         comment                                  user  tag\n",
       "51893  61574892   922644     5.0  Para mi fue una fuente continua de información útil para aplicar, todos los mensajes son claros y precisos, encontré mucho para mejorar, entendí porque pierdo el interés en la mayoría de las presentaciones empresariales y que no debo ser el único. Totalmente para recomendar!!!\\n\\nPD: Algunos temas quizás sea bueno dividirlos, especialmente aquellos que durán más de 5 a 7 minutos.                      Mariano Buñirigo  pos\n",
       "70521   2606180   166170     4.5                                                                                                                                                                                                                                                                                                                                                            Da uma visão clara sobre o negocíos.             Roseana Santos de Freitas  pos\n",
       "63186  35583622   749262     4.0                                                                                                                                                                                                                                                                                                                                            Me ayudo a entender mucho algunas cosas que no sabia  Lorenzo Santiago Saul Arias Villegas  neg\n",
       "77793  80370794  3314342     5.0                                                                                                                                                                                                                                                                                                                                               Es un excelente curso, enseñas muy bien, gracias.                                 Kevin  pos\n",
       "67355  80597074  1254714     4.0                                                                                                                                                                                                                                                                                                                             fue buena pero demaciada explicacion un poko confusa pero necesaria         Alexis Fernando Espinoza Arce  neg\n",
       "25409  65666142  3332670     5.0                                                                                                                                                                                                                              me parecio muy bueno,pero me hubiera gustado que explicara los tonos para cada tipo d piel y cuando se tiene q hacer de nuevo o como saber si es al ano o algo asi                      Elizabeth Aranda  pos\n",
       "20194  60168386  2096652     5.0                                                                                                                                                                                                                                                                                                                          muy buen curso a persa que se aborda no profundiza me paresio muy buen      Paulina Guadalupe López Espinoza  pos\n",
       "6207   72222592  1133110     5.0                                                                                                                                                                                                                                                                Perfecto, el profesor es muy atento y ayuda con lo que puede. se aprende bastante, mucho mejor que otros cursos del mismo nivel.               Jose Manuel Lopez Gomez  pos\n",
       "6887   57956543  1363082     5.0                                                                                                                                                                                                                                                                                                                                                                      MUY BUENO, EXCELENTE!!!!!!                    Robeff Angel Darío  pos\n",
       "43301  68937214  2426324     5.0                                                                                                                                                                                                                                                                                                                                fue muy buena eleccion avian cosas que me costaban y las entendi                         Soledad Garro  pos"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_news = pd.read_pickle(\"udemy_reviews.pkl\")\n",
    "# Aplica pos/neg\n",
    "df_news['tag']=df_news['rating'].apply(lambda x: 'pos' if x > 4 else 'neg')\n",
    "# Filtra los que solamente dicen una palabra (ej. \"Excelente!\")\n",
    "df_news = df_news[df_news['comment'].str.contains(\"\\s\")]\n",
    "# Filtra los que dicen menos de 12 letras (ej. \"Excelente!\")\n",
    "df_news = df_news[df_news['comment'].str.len() >= 12]\n",
    "df_news = df_news.sample(2000)\n",
    "df_news.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "bflY9AU1Vbh5",
    "outputId": "e02e8a64-4434-4162-f679-59f8b2592513"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2000 entries, 7767 to 67010\n",
      "Data columns (total 6 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   id       2000 non-null   int64  \n",
      " 1   course   2000 non-null   int64  \n",
      " 2   rating   2000 non-null   float64\n",
      " 3   comment  2000 non-null   object \n",
      " 4   user     2000 non-null   object \n",
      " 5   tag      2000 non-null   object \n",
      "dtypes: float64(1), int64(2), object(3)\n",
      "memory usage: 109.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_news.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F6qwR5CAahLp"
   },
   "source": [
    "#Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wbCEhthGasEn"
   },
   "source": [
    "We defined a list of custom words to be exclude from our dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h8EP2Md3FcQr"
   },
   "source": [
    "Create the cleaner function to clean the spanish text, remove non alpha numeric characters, remove duplicate, remove spanish accutes, remove digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Faolin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Faolin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aaaaa']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st = ['aaaaa','asd','asdadsad']\n",
    "y = ['aa','bbb','ccc']\n",
    "[x for x in st if any(string for string in y if string in x)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "stop = set(stopwords.words('spanish'))\n",
    "\n",
    "black_list = ['excelen', 'buen',\n",
    "              'muchas', 'graci'\n",
    "              ]\n",
    "\n",
    "additional_stopwords=set(black_list)\n",
    "\n",
    "stopwords_sp = stop.union(additional_stopwords)\n",
    "\n",
    "from nltk.stem import SnowballStemmer\n",
    "spanish_stemmer = SnowballStemmer('spanish')\n",
    "def stemmization(texts):\n",
    "    texts = re.sub(r\"\"\"\n",
    "                   [,.;@#?!&$]+  # Accept one or more copies of punctuation\n",
    "                   \\ *           # plus zero or more copies of a space,\n",
    "                   \"\"\",\n",
    "                   \" \",          # and replace it with a single space\n",
    "                   texts, flags=re.VERBOSE)\n",
    "    return spanish_stemmer.stem(texts).split()\n",
    "\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('es_core_news_md')\n",
    "def lemmatization(texts, allowed_postags=['NOUN']):\n",
    "    #x = nlp(texts)\n",
    "    #print([(xx.text,xx.pos_) for xx in x])\n",
    "    texts_out = [ token.text for token in nlp(texts) if token.pos_ in \n",
    "                 allowed_postags and token.text not in black_list and len(token.text)>2]\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 329 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bigram = gensim.models.Phrases(df_news['comment'].to_list()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H_7Un4fSFbdC"
   },
   "outputs": [],
   "source": [
    "def cleaner(word):\n",
    "    word = re.sub(r'((http|https)\\:\\/\\/)?[a-zA-Z0-9\\.\\/\\?\\:@\\-_=#]+\\.([a-zA-Z]){2,6}([a-zA-Z0-9\\.\\&\\/\\?\\:@\\-_=#])*', '', word, flags=re.MULTILINE)\n",
    "    word = re.sub(r'(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', \"\", word)\n",
    "    word = re.sub(r'ee.uu', 'eeuu', word)\n",
    "    word = re.sub(r'\\#\\.', '', word)\n",
    "    word = re.sub(r'\\n', '', word)\n",
    "    word = re.sub(r',', ' ', word)\n",
    "    word = re.sub(r'\\-', ' ', word)\n",
    "    word = re.sub(r'\\.{3}', ' ', word)\n",
    "    word = re.sub(r'a{2,}', 'a', word)\n",
    "    word = re.sub(r'é{2,}', 'é', word)\n",
    "    word = re.sub(r'i{2,}', 'i', word)\n",
    "    word = re.sub(r'ja{2,}', 'ja', word) \n",
    "    word = re.sub(r'á', 'a', word)\n",
    "    word = re.sub(r'é', 'e', word)\n",
    "    word = re.sub(r'í', 'i', word)\n",
    "    word = re.sub(r'ó', 'o', word)\n",
    "    word = re.sub(r'ú', 'u', word)  \n",
    "    word = re.sub('[^a-zA-Z]', ' ', word)\n",
    "    wordlist = [ token for token in nltk.word_tokenize(word) if token.lower() not in stopwords_sp and len(token)>3 ]\n",
    "    wordlist = [x for x in wordlist if not any(string for string in black_list if string in x)]\n",
    "    word = \" \".join(wordlist)\n",
    "    list_word_clean = []\n",
    "    for w1 in word.split(r\"\\s\"):\n",
    "        if  w1.lower() not in stopwords_sp:\n",
    "            list_word_clean.append(w1.lower())\n",
    "\n",
    "    bigram_list = bigram[list_word_clean]\n",
    "    out_text = stemmization(\" \".join(bigram_list))\n",
    "    return out_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hola', 'germen', 'tendria', 'pulgas', 'cre']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaner('hola soy un gérmen y tendría pulgas. Pero no,creo que no. O si. excelente! excelente')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vmgAfhN6bWrR"
   },
   "source": [
    "Create the function for select **only nouns** for our data, this way we are removing adverb, adjetives, verbs, etc. This is doing with spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3wMjzGX9bscx"
   },
   "source": [
    "For gensim we need a list of text, so we need do convert the dataframe to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hola',\n",
       " 'soy',\n",
       " 'un',\n",
       " 'germen',\n",
       " 'y',\n",
       " 'tendria',\n",
       " 'pulgas',\n",
       " 'pero',\n",
       " 'no',\n",
       " 'creo',\n",
       " 'que',\n",
       " 'no',\n",
       " 'o',\n",
       " 'si']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmization('hola soy un gérmen y tendría pulgas. Pero no,creo que no. O si')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gérmen', 'pulgas']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatization('hola soy un gérmen y tendría pulgas. Pero no,creo que no. O si')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "IZhWiKxY4Gx2",
    "outputId": "0de89bb9-dc2e-470e-d996-40992ae55e5c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "kJzcwy4ORHD1",
    "outputId": "689b6dc6-ab0a-490d-8700-ac5f1096cb0c"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "colab_type": "code",
    "id": "HciZjXBfwbXM",
    "outputId": "15c4c7c2-a97e-4c33-9922-7922d5410abe"
   },
   "outputs": [],
   "source": [
    "# !python -m spacy download es_core_news_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "yDBAXRQuOnOG",
    "outputId": "a034c4d9-a10d-4db3-a60c-8435eeaa8935"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13092    Gracias por estos sencillos consejos de Flexbox, la verdad me sirvieron de mucho. Saludos!!!\n",
       "63917            Excelente explicación y dominio del tema, ejemplos prácticos y de fácil aprendizaje.\n",
       "15768                                    excelente curso, felicitaciones al profesor.\\nMuchas gracias\n",
       "Name: comment, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news['comment'].sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "2vyiSwQjPCox",
    "outputId": "6577c4eb-29d3-46f8-c5a2-15fbc10576d4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['excelente', 'aclare', 'dudas', 'respecto', 'tem']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaner(df_news['comment'].iloc[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3FqIi24ISgK2"
   },
   "source": [
    "The Cleaner function work properly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yjMX0qS4SmUR"
   },
   "source": [
    "##### Let's clean all the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TBDM5Caomutj"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e4cd168ff65444b9616829cb8518ef8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "df_news['comment_cleaned'] = df_news['comment'].progress_apply(cleaner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7egM0YZzRS9r"
   },
   "source": [
    "Now we need to build the *corpus* and the *dictionary* that gensim need to work, to do that we need to pass a list of list of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45448                                                                                                      [profesor, entiende, bien, palabras, acelera, traduce, spanish, english]\n",
       "29693                                                              [bien, metodologia, manera, enfocar, contenidos, aprendizaje, permite, imprimir, certificado, visualiza, opcion]\n",
       "24716                                                                                                                                         [profesor, experiencia, sabe, explic]\n",
       "24324                                                                                                                                                   [curso, dinamico, entreten]\n",
       "9710                                                                                                                                                           [explica, paso, pas]\n",
       "12482                          [informacion, presentada, manera, concisa, concreta, acompa, graficas, permiten, digerir, informacion, manera, sencilla, amena, corto, lapso, tiemp]\n",
       "68855                                                                                                                                                 [curso, basico, bien, explic]\n",
       "19250    [curso, aunque, seccion, rutas, senti, largo, mismo, orden, tenian, secciones, anteriores, quiere, decir, negativo, malo, solo, percepcion, siguio, misma, linea, seccion]\n",
       "6153                                                                                                                               [ahora, logrado, entender, claridad, tema, trat]\n",
       "31562                                       [practico, directo, recomendableaunque, videos, volumen, queda, bajo, escucha, perfectamente, explicaciones, instructor, claras, graci]\n",
       "Name: comment_cleaned, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news['comment_cleaned'].iloc[200:210]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DZmxTdsYTV35"
   },
   "outputs": [],
   "source": [
    "dictionary = Dictionary(df_news['comment_cleaned'].to_list())\n",
    "dictionary.compactify()\n",
    "# Filter extremes\n",
    "#dictionary.filter_extremes(no_below=5, no_above=0.3)#, keep_n=10000)\n",
    "#dictionary.filter_extremes(no_below=2, no_above=0.97, keep_n=None)\n",
    "dictionary.filter_extremes(no_below=5, no_above=0.2, keep_n=None)\n",
    "dictionary.compactify()\n",
    "\n",
    "corpus = [dictionary.doc2bow(text) for text in df_news['comment_cleaned'].to_list()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NgV46EUdSu0n"
   },
   "source": [
    "# Now let's do the modeling part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GWsxgxE8-YWC"
   },
   "source": [
    "We are comparing 3 topic modeling algorithm Latent Dirichlet Allocation (LDA), Latent\n",
    "semantic analysis (LSA), Hierarchical Dirichlet Process\n",
    "(HDP),in order to evaluate topic models we will be using **topic coherence**, which is a measure of how\n",
    "interpretable topics are for human beings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install pyLDAvis==2.1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Faolin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Faolin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot  as plt\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import gensim\n",
    "from gensim.models import CoherenceModel, LdaModel, LsiModel, HdpModel\n",
    "#from gensim.models.wrappers import LdaMallet\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim import corpora\n",
    "\n",
    "import pyLDAvis.gensim\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "import os, re, operator, warnings\n",
    "warnings.filterwarnings('ignore')  \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsamodel = LsiModel(corpus=corpus, num_topics=25, id2word=dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '-0.782*\"bien\" + -0.236*\"explicado\" + -0.141*\"excelente\" + -0.139*\"explica\"'),\n",
       " (1, '0.587*\"excelente\" + -0.432*\"bien\" + 0.291*\"curs\" + -0.185*\"explicado\"'),\n",
       " (2,\n",
       "  '-0.657*\"excelente\" + -0.246*\"curs\" + 0.244*\"instructor\" + -0.202*\"bien\"'),\n",
       " (3,\n",
       "  '-0.544*\"instructor\" + 0.249*\"bastante\" + 0.231*\"profesor\" + 0.176*\"entender\"'),\n",
       " (4,\n",
       "  '-0.564*\"explica\" + -0.489*\"curs\" + 0.416*\"explicacion\" + -0.211*\"profesor\"'),\n",
       " (5, '-0.586*\"curs\" + 0.438*\"explica\" + 0.371*\"claro\" + -0.205*\"explicado\"'),\n",
       " (6,\n",
       "  '-0.766*\"explicacion\" + -0.326*\"curs\" + 0.238*\"excelente\" + -0.186*\"clara\"'),\n",
       " (7, '0.754*\"claro\" + 0.302*\"curs\" + -0.277*\"explica\" + -0.129*\"excelente\"'),\n",
       " (8, '0.393*\"entender\" + 0.358*\"cosas\" + -0.290*\"profesor\" + 0.248*\"facil\"'),\n",
       " (9, '0.461*\"facil\" + 0.401*\"explicado\" + -0.258*\"cosas\" + -0.221*\"explic\"')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsamodel.print_topics(10,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldamodel = LdaModel(corpus=corpus, num_topics=25, id2word=dictionary, iterations = 2000, passes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(17,\n",
       "  '0.030*\"parecio\" + 0.027*\"conocimientos\" + 0.023*\"excelente\" + 0.022*\"ense\" + 0.022*\"primer\" + 0.021*\"deja\"'),\n",
       " (3,\n",
       "  '0.047*\"cosas\" + 0.046*\"forma\" + 0.038*\"aprendido\" + 0.027*\"explicaciones\" + 0.023*\"bien\" + 0.018*\"clara\"'),\n",
       " (22,\n",
       "  '0.099*\"interesante\" + 0.028*\"gustado\" + 0.027*\"cursos\" + 0.026*\"ense\" + 0.020*\"principi\" + 0.018*\"graci\"'),\n",
       " (7,\n",
       "  '0.100*\"parece\" + 0.047*\"mucha\" + 0.045*\"buena\" + 0.041*\"recom\" + 0.037*\"conocimiento\" + 0.025*\"explicacion\"'),\n",
       " (9,\n",
       "  '0.051*\"completo\" + 0.041*\"sido\" + 0.040*\"ahora\" + 0.040*\"claro\" + 0.038*\"profesor\" + 0.037*\"sencillo\"'),\n",
       " (23,\n",
       "  '0.089*\"entender\" + 0.028*\"rapido\" + 0.027*\"facil\" + 0.027*\"falta\" + 0.025*\"explicar\" + 0.023*\"simple\"'),\n",
       " (14,\n",
       "  '0.050*\"bien\" + 0.019*\"aprendiendo\" + 0.019*\"programacion\" + 0.018*\"software\" + 0.017*\"nuevas\" + 0.016*\"iniciacion\"'),\n",
       " (19,\n",
       "  '0.218*\"explicacion\" + 0.076*\"clara\" + 0.061*\"momento\" + 0.024*\"basicos\" + 0.022*\"manera\" + 0.020*\"entiende\"'),\n",
       " (21,\n",
       "  '0.023*\"programacion\" + 0.022*\"instructor\" + 0.020*\"alguna\" + 0.020*\"bien\" + 0.019*\"general\" + 0.018*\"mejor\"'),\n",
       " (6,\n",
       "  '0.240*\"curs\" + 0.125*\"excelente\" + 0.071*\"bi\" + 0.058*\"explica\" + 0.038*\"introduccion\" + 0.020*\"profesor\"')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldamodel.print_topics(10, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YwiwW86Man80"
   },
   "source": [
    " ## Hierarchical Dirichlet process Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "opxvCwJcbIs9"
   },
   "outputs": [],
   "source": [
    "hdpmodel = HdpModel(corpus=corpus, id2word=dictionary, random_state= 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KON8iJfmS-f7"
   },
   "source": [
    "and the topics of this model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ewKUhhpgjo8g"
   },
   "outputs": [],
   "source": [
    "def display_topics(model, model_type=\"lda\"):\n",
    "    for topic_idx, topic in enumerate(model.print_topics()):\n",
    "        print (\"Topic %d:\" % (topic_idx))\n",
    "        if model_type== \"hdp\":\n",
    "            print (\" \".join(re.findall( r'\\*(.[^\\*-S]+).?', topic[1])), \"\\n\")\n",
    "        else:\n",
    "            print (\" \".join(re.findall( r'\\\"(.[^\"]+).?', topic[1])), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "-1pogQLHbSl9",
    "outputId": "94002da5-32a7-4c25-b5ac-29b23b8e5959"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "toda  bueno  visto  habia  siendo  lenguaje  clar  entienda  bast  photoshop \n",
      "\n",
      "Topic 1:\n",
      "bien  demas  resultado  iniciarse  deberia  todas  utilidad  temas  basicas  equipo \n",
      "\n",
      "Topic 2:\n",
      "dado  vida  nivel  conten  practicos  aprende  hablando  encuentro  llevo  real \n",
      "\n",
      "Topic 3:\n",
      "ejercicios  expectativas  bases  profesor  necesario  comprar  actividades  algun  proyectos  cantidad \n",
      "\n",
      "Topic 4:\n",
      "empieza  viene  explicar  practicas  recien  pronunciacion  explicacion  final  bi  calificacion \n",
      "\n",
      "Topic 5:\n",
      "ayudado  temas  podria  gratuito  cosas  explicado  actividades  explica  cosa  responde \n",
      "\n",
      "Topic 6:\n",
      "repasar  herramientas  dominio  hice  conocimiento  calidad  mundo  pienso  cero  persona \n",
      "\n",
      "Topic 7:\n",
      "parecido  mala  aplicacion  principiantes  ando  explicando  detallado  recomendable  dado  trabajo \n",
      "\n",
      "Topic 8:\n",
      "primer  varios  ayudan  termine  tipo  encima  practicar  deja  video  cortos \n",
      "\n",
      "Topic 9:\n",
      "dedicacion  conciso  contenido  puesto  aspectos  entender  introduccion  objetivo  concepto  ocasiones \n",
      "\n",
      "Topic 10:\n",
      "leccion  basicas  creacion  recom  proyectos  final  program  siendo  expl  mismo \n",
      "\n",
      "Topic 11:\n",
      "necesitaba  util  perfecto  habia  unas  mismo  concreto  detalles  estudiantes  tips \n",
      "\n",
      "Topic 12:\n",
      "autor  quiero  linux  pract  seguir  bi  alguna  lleva  quede  herramientas \n",
      "\n",
      "Topic 13:\n",
      "desarrollar  poner  empezando  necesitaba  deja  trabaj  atento  clar  peque  parte \n",
      "\n",
      "Topic 14:\n",
      "hizo  didact  recomendado  pronunciacion  concreto  practicar  materiales  trabajo  ideas  aprender \n",
      "\n",
      "Topic 15:\n",
      "informacion  empezando  bootstrap  cosas  aplicar  sirvio  mucha  adquirir  titulo  unas \n",
      "\n",
      "Topic 16:\n",
      "material  practicas  fernando  quiza  perfeccion  final  learning  salud  recomend  recomendable \n",
      "\n",
      "Topic 17:\n",
      "problema  aspectos  youtube  dejar  nunca  entendido  videos  necesito  pude  acerca \n",
      "\n",
      "Topic 18:\n",
      "ahorita  this  conceptos  ejercicios  actualizar  udemy  manejo  idea  encima  marketing \n",
      "\n",
      "Topic 19:\n",
      "instructor  practica  detall  mejor  conocimiento  profesional  entienda  actividades  quizas  falto \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# hdpmodel.show_topics() \n",
    "\n",
    "display_topics(hdpmodel, model_type=\"hdp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jd3LspvVUEXj"
   },
   "source": [
    "as we could see there are 20 topics, however is kind of dificult to interpret or follow, so we decide to move to another model.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4J2IIPqHVTzZ"
   },
   "outputs": [],
   "source": [
    "def evaluate_graph(dictionary, corpus, texts, limit, model):\n",
    "    \"\"\"\n",
    "    Function to display num_topics - LDA graph using c_v coherence\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    limit : topic limit\n",
    "    \n",
    "    Returns:\n",
    "    -------\n",
    "    lm_list : List of LDA topic models\n",
    "    c_v : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    c_v = []\n",
    "    lm_list = []\n",
    "    for num_topics in range(1, limit):\n",
    "        if model == 'lsi':\n",
    "            lm = LsiModel(corpus=corpus, num_topics=num_topics, id2word=dictionary)\n",
    "        else:\n",
    "            lm = LdaModel(corpus=corpus, num_topics=num_topics, id2word=dictionary)\n",
    "        lm_list.append(lm)\n",
    "        cm = CoherenceModel(model=lm, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        c_v.append(cm.get_coherence())\n",
    "        \n",
    "    # Show graph\n",
    "    x = range(1, limit)\n",
    "    plt.plot(x, c_v)\n",
    "    plt.xlabel(\"num_topics\")\n",
    "    plt.ylabel(\"Coherence score\")\n",
    "    plt.legend((\"c_v\"), loc='best')\n",
    "    plt.show()\n",
    "    \n",
    "    return lm_list, c_v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hse2o99bZ8wi"
   },
   "source": [
    "##LSI MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HFQCfc9VcmT7"
   },
   "outputs": [],
   "source": [
    "lsimodel = LsiModel(corpus=corpus, num_topics=10, id2word=dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "colab_type": "code",
    "id": "yfrJmKuLaUrg",
    "outputId": "b7add73d-8ca9-41fb-b93f-eb4de56773dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "bien explicado explica explic excelente profesor facil instructor curs temas \n",
      "\n",
      "Topic 1:\n",
      "bien excelente curs explic explicacion instructor temas explicado explica manera \n",
      "\n",
      "Topic 2:\n",
      "excelente curs explica temas profesor solo bien hace explic videos \n",
      "\n",
      "Topic 3:\n",
      "explicacion curs facil explica clara entender profesor explicado manera tema \n",
      "\n",
      "Topic 4:\n",
      "temas explica curs profesor solo visto tema informacion explicado explicacion \n",
      "\n",
      "Topic 5:\n",
      "facil explica manera informacion curs explicado entender explic explicacion herramientas \n",
      "\n",
      "Topic 6:\n",
      "curs excelente explica temas informacion solo explicacion instructor parte explicado \n",
      "\n",
      "Topic 7:\n",
      "explicacion informacion profesor eleccion facil gran curs explica entender conceptos \n",
      "\n",
      "Topic 8:\n",
      "claro eleccion momento curs explicado parte temas excelente instructor paso \n",
      "\n",
      "Topic 9:\n",
      "informacion explica claro bastante eleccion explicado cosas curs ense clara \n",
      "\n"
     ]
    }
   ],
   "source": [
    "display_topics(lsimodel)  # Showing the topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t-Bt22W-r1ZO"
   },
   "source": [
    "It seen that with 10 topics there is some themes with keywords related to: trump, venezuela, police, electiones, terrorism; still is a little difficult to gt some insight, because of this we are trying to select the best number of topics by iterate over a range of values and looking the coherence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 318
    },
    "colab_type": "code",
    "id": "dtXS4IfIVYIJ",
    "outputId": "916f153b-dc7d-4484-8a62-b9be3a788328"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "lmlist_lsi, c_v = evaluate_graph(dictionary=dictionary, corpus=corpus, texts=df_news['comment_cleaned'].to_list(), limit=21, model= \"lsi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kmzyPFWiw63V"
   },
   "source": [
    "According to the coherence the best number of topics are between 3-7, however you must select the topics using both the coherence and visual inspection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "TczLrG1ZRL4_",
    "outputId": "97713743-960a-4570-b917-63cd2437b058"
   },
   "outputs": [],
   "source": [
    "display_topics(lmlist_lsi[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v6ty9sFNyRyG"
   },
   "source": [
    "Now, Let's try another model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "earp2d28dz3a"
   },
   "source": [
    "## Latent Dirichlet Allocation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wiI55UzIdnUN"
   },
   "outputs": [],
   "source": [
    "ldamodel = LdaModel(corpus=corpus, num_topics=10, id2word=dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "colab_type": "code",
    "id": "fjAbhPAMd7_B",
    "outputId": "6128b18b-dcda-4960-8e98-ab2fa440b5de"
   },
   "outputs": [],
   "source": [
    "display_topics(ldamodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2cywaW1QsJ8N"
   },
   "source": [
    "Find out the optimal number of topics for the LDA model based on the coherence metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 318
    },
    "colab_type": "code",
    "id": "Rd651y6mWpTF",
    "outputId": "18376c3d-d18a-465e-d115-9b2b55c02005"
   },
   "outputs": [],
   "source": [
    "%%timer\n",
    "lmlist, c_v = evaluate_graph(dictionary=dictionary, corpus=corpus, texts=df_news['comment_cleaned'].to_list(), limit=21, model= \"lda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P0T4UJGmyiLp"
   },
   "source": [
    "For this model it seems that  9 or 18, again we must to check the keywords too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S6S88TE0eslU"
   },
   "source": [
    "### Comparing the Model Coherence of the Best Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6dnp010Wz6Xo"
   },
   "source": [
    "we made 3 models, now let's compare each other's  coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s0bosG67ev6L"
   },
   "outputs": [],
   "source": [
    "ldamodel = lmlist[11]\n",
    "lsimodel = lmlist_lsi[2]\n",
    "\n",
    "lsitopics = [[word for word, prob in topic] for topicid, topic in lsimodel.show_topics(formatted=False)]\n",
    "\n",
    "hdptopics = [[word for word, prob in topic] for topicid, topic in hdpmodel.show_topics(formatted=False)]\n",
    "\n",
    "ldatopics = [[word for word, prob in topic] for topicid, topic in ldamodel.show_topics(formatted=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IP5GpYG1e4nT"
   },
   "outputs": [],
   "source": [
    "lsi_coherence = CoherenceModel(topics=lsitopics[:10], texts=df_news['comment_cleaned'].to_list(), dictionary=dictionary, window_size=10).get_coherence()\n",
    "\n",
    "hdp_coherence = CoherenceModel(topics=hdptopics[:10], texts=df_news['comment_cleaned'].to_list(), dictionary=dictionary, window_size=10).get_coherence()\n",
    "\n",
    "lda_coherence = CoherenceModel(topics=ldatopics, texts=df_news['comment_cleaned'].to_list(), dictionary=dictionary, window_size=10).get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "colab_type": "code",
    "id": "XntcwwKufZTp",
    "outputId": "7278380a-d093-4908-a44a-0ba94a2d7aac"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "coherences = [lsi_coherence, hdp_coherence, lda_coherence]\n",
    "n = len(coherences)\n",
    "x = ['lsi_coherence','hdp_coherence', 'lda_coherence']\n",
    "sns.barplot(x, coherences)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bXKu-wAoFMRY"
   },
   "source": [
    "We can see that the **LdaModel** model **with 8 topics** has the higher value of\n",
    "coherence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B5Ii_TedVNHq"
   },
   "source": [
    "Examine the keyword to get the topics of the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 629
    },
    "colab_type": "code",
    "id": "qtOtsGxHuD8W",
    "outputId": "841b40c9-401d-4e5e-a6bc-cf6e1d7a7169"
   },
   "outputs": [],
   "source": [
    "\n",
    "display_topics(ldamodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "23tYxCUIchga"
   },
   "source": [
    "It looks like the topics are:\n",
    "* Topic 0: felicitaciones\n",
    "* Topic 1: expectativas\n",
    "* Topic 2: experiencia\n",
    "* Topic 3: contenido\n",
    "* Topic 4: instructor\n",
    "* Topic 5: material\n",
    "* Topic 6: video\n",
    "* Topic 7: lenguaje\n",
    "* Topic 8: ejercicios\n",
    "* Topic 9: titulo\n",
    "* Topic 10: temas\n",
    "* Topic 11: explicación\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dicc = {0:'felicitaciones', 1:'expectativas', 2:'experiencia', 3: 'contenido', 4:'instructor', 5:'material', 6:'video', \n",
    "              7:'lenguaje', 8:'ejercicios', 9: 'titulo', 10:'temas', 11:'explicación'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v0aL-yqAFzUS"
   },
   "source": [
    "Let´s check the keyword when we selecting another number of topics (14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AGXxaEtVudnc"
   },
   "outputs": [],
   "source": [
    "ldamodel_16 =lmlist[16]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 680
    },
    "colab_type": "code",
    "id": "aS3QJ5KV5z_c",
    "outputId": "1d87fea1-bfa5-476a-e472-a7e585bd8cf3"
   },
   "outputs": [],
   "source": [
    "display_topics(ldamodel_16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u2clSiIF1yHy"
   },
   "source": [
    "# Classifiying all documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_sLVX03-1_GB"
   },
   "source": [
    "now that we have been select the best model and topics number, is time to assign a topic to each document, means **cluster** according to the topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9fojFPHKW204"
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm_notebook\n",
    "\n",
    "def format_topics_sentences(ldamodel=0, corpus=corpus, texts=0):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()-n\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row in tqdm_notebook(enumerate(ldamodel[corpus]), total=len(ldamodel[corpus])):\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)\n",
    "\n",
    "\n",
    "df_topic_sents_keywords = format_topics_sentences(ldamodel, corpus=corpus, texts=df_news['comment_cleaned'].to_list())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "id": "E8FofLvzYmTP",
    "outputId": "1f5226b4-02cf-4243-e7a1-ab89ddb707b5"
   },
   "outputs": [],
   "source": [
    "# Format\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "\n",
    "# Show\n",
    "df_dominant_topic.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9vtBDBQKkzmK"
   },
   "source": [
    "We selected the ldamodel with 12 topics and asigned a dominant topic to each document, now let map each topic with a label "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z8f8u5UJlQJ8"
   },
   "source": [
    "first let's create the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I27y-Pd-lXL8"
   },
   "outputs": [],
   "source": [
    "label_dicc = {0:'felicitaciones', 1:'expectativas', 2:'experiencia', 3: 'contenido', 4:'instructor', 5:'material', 6:'video', \n",
    "              7:'lenguaje', 8:'ejercicios', 9: 'titulo', 10:'temas', 11:'explicación'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qUspHFcPopTz"
   },
   "outputs": [],
   "source": [
    "df_dominant_topic['Dominant_Topic'] = df_dominant_topic['Dominant_Topic'].astype('int64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "id": "o9XM5yHgnmg5",
    "outputId": "1d89e87e-a9e1-401e-edd1-63457a7f50c4"
   },
   "outputs": [],
   "source": [
    "df_dominant_topic['Dominant_Topic'] = df_dominant_topic['Dominant_Topic'].map(label_dicc)\n",
    "df_dominant_topic.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "in5E52W3pl_k"
   },
   "outputs": [],
   "source": [
    "df_news['labels'] = df_dominant_topic['Dominant_Topic']\n",
    "df_news['label_confidence'] = df_dominant_topic['Topic_Perc_Contrib']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mA35orWWqQMt"
   },
   "source": [
    "Let's examine some text and its topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 335
    },
    "colab_type": "code",
    "id": "7cHF6NEHkHYh",
    "outputId": "8141df9c-6d26-4d3d-d6d9-9643da78a7c7"
   },
   "outputs": [],
   "source": [
    "df_news[['comment', 'labels']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 115
    },
    "colab_type": "code",
    "id": "sgkBFTYbqID0",
    "outputId": "cb7ce341-6c49-48c3-eb15-cccb8a5ea902"
   },
   "outputs": [],
   "source": [
    "df_news[ df_news['labels'] == 'instructor'].sort_values(by='label_confidence',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_news.sort_values(by='label_confidence',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dCc6-oIo6BMw"
   },
   "source": [
    "### let's see the distribution of topics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "colab_type": "code",
    "id": "VOitT-s10yv5",
    "outputId": "16a4b62a-dd36-4607-a55b-ad77f80acf65"
   },
   "outputs": [],
   "source": [
    "ax = df_dominant_topic['Dominant_Topic'].value_counts().plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jh0l7ngJ6J12"
   },
   "source": [
    "The topis are almost balanced, so we are good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AcWRIAWTWhl7"
   },
   "source": [
    "finally that we have our models set up, as well as analyzed, we can go\n",
    "ahead to visualizing them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 521
    },
    "colab_type": "code",
    "id": "Jv3PFRwBs-gT",
    "outputId": "6749bc00-2549-4857-d0bd-df8540c8accd"
   },
   "outputs": [],
   "source": [
    "!pip install pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jXpx66NTd1uT"
   },
   "outputs": [],
   "source": [
    "import pyLDAvis\n",
    "\n",
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 991
    },
    "colab_type": "code",
    "id": "diu2MLik41sf",
    "outputId": "078af8ba-2310-4875-c8de-e24a06ee6340"
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "import pyLDAvis.gensim\n",
    "pyLDAvis.gensim.prepare(ldamodel, corpus, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "topic_modeling_spanish.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
