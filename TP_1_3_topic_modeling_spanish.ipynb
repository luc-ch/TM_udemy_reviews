{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zbQv8f_tjWq4"
   },
   "source": [
    "In this article we will implementing topics model with gensim, topic models are \n",
    "probabilistic models which contains information about topics in the\n",
    "text. A topic is like theme, or in other words underlying ideas represented in text. \n",
    "For example, we are working with a corpus of **spanish newspaper articles**,\n",
    "possible topics would be  politics, conflicts, elections and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V0UBlkyp_gme"
   },
   "source": [
    "#### Load the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ui5Uo0hn_eGm"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim\n",
    "import numpy as np\n",
    "from gensim.models import CoherenceModel, LdaModel, LsiModel, HdpModel\n",
    "from gensim.corpora import Dictionary\n",
    "# from gensim.models.wrappers import LdaMallet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SBS3r7AFAEtg"
   },
   "source": [
    "### Connect to drive to get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 162
    },
    "colab_type": "code",
    "id": "550zxhdVCl6y",
    "outputId": "8e6c130a-bccd-47e4-c00d-d8c22ff325ce"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>course</th>\n",
       "      <th>rating</th>\n",
       "      <th>comment</th>\n",
       "      <th>user</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10385</th>\n",
       "      <td>54809352</td>\n",
       "      <td>291766</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Fue muy interesante y de mucha ayuda para realizar un trabajo realizado para estudio de factibilidad</td>\n",
       "      <td>Fanny Paulina Prado Paucar</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31644</th>\n",
       "      <td>38096942</td>\n",
       "      <td>1803800</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Excelente CURSO! Herramientas que necesitaba! muchas gracias de todo corazon</td>\n",
       "      <td>Karina soledad Infante</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31684</th>\n",
       "      <td>17844716</td>\n",
       "      <td>1444542</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Excelente curso !!!</td>\n",
       "      <td>Sebastián Bermúdez</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77952</th>\n",
       "      <td>73119188</td>\n",
       "      <td>826602</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Considero que es muy bueno, existen temas que desconocía y estoy comprendiendo todo</td>\n",
       "      <td>Dulce María Hernández Morales</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29716</th>\n",
       "      <td>64870050</td>\n",
       "      <td>1209326</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Fueron conceptos muy generales y claros a ese nivel.</td>\n",
       "      <td>Carlos Castillo</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58101</th>\n",
       "      <td>86748372</td>\n",
       "      <td>296890</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Muy completo el curso, empieza desde cero y claras las explicaciones.</td>\n",
       "      <td>Diana Milena Tapias Torres</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29814</th>\n",
       "      <td>42532720</td>\n",
       "      <td>1209326</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Fue buena elección por que dá un vistazo global</td>\n",
       "      <td>Jorge Gomez</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12751</th>\n",
       "      <td>81127750</td>\n",
       "      <td>976214</td>\n",
       "      <td>4.0</td>\n",
       "      <td>El curso menciona muy bien la propiedad CSS, aunque ya esta desactualizado y estaría mejor una mejora al contenido</td>\n",
       "      <td>Jovan Gomez</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69259</th>\n",
       "      <td>5083384</td>\n",
       "      <td>233830</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Aun estamos en aspectos básicos.</td>\n",
       "      <td>Luis Paez Rocha</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69980</th>\n",
       "      <td>95363718</td>\n",
       "      <td>1854894</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Esta muy bien explicado y me gusta que dejen tarea.</td>\n",
       "      <td>Jose Alexis Cruz Garcia</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id   course  rating                                                                                                             comment                           user  tag\n",
       "10385  54809352   291766     5.0                Fue muy interesante y de mucha ayuda para realizar un trabajo realizado para estudio de factibilidad     Fanny Paulina Prado Paucar  pos\n",
       "31644  38096942  1803800     5.0                                        Excelente CURSO! Herramientas que necesitaba! muchas gracias de todo corazon         Karina soledad Infante  pos\n",
       "31684  17844716  1444542     5.0                                                                                                 Excelente curso !!!             Sebastián Bermúdez  pos\n",
       "77952  73119188   826602     5.0                                 Considero que es muy bueno, existen temas que desconocía y estoy comprendiendo todo  Dulce María Hernández Morales  pos\n",
       "29716  64870050  1209326     5.0                                                                Fueron conceptos muy generales y claros a ese nivel.                Carlos Castillo  pos\n",
       "58101  86748372   296890     5.0                                               Muy completo el curso, empieza desde cero y claras las explicaciones.     Diana Milena Tapias Torres  pos\n",
       "29814  42532720  1209326     4.5                                                                     Fue buena elección por que dá un vistazo global                    Jorge Gomez  pos\n",
       "12751  81127750   976214     4.0  El curso menciona muy bien la propiedad CSS, aunque ya esta desactualizado y estaría mejor una mejora al contenido                    Jovan Gomez  neg\n",
       "69259   5083384   233830     2.0                                                                                    Aun estamos en aspectos básicos.                Luis Paez Rocha  neg\n",
       "69980  95363718  1854894     5.0                                                                 Esta muy bien explicado y me gusta que dejen tarea.        Jose Alexis Cruz Garcia  pos"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_news = pd.read_pickle(\"udemy_reviews.pkl\")\n",
    "# Aplica pos/neg\n",
    "df_news['tag']=df_news['rating'].apply(lambda x: 'pos' if x > 4 else 'neg')\n",
    "# Filtra los que solamente dicen una palabra (ej. \"Excelente!\")\n",
    "df_news = df_news[df_news['comment'].str.contains(\"\\s\")]\n",
    "# Filtra los que dicen menos de 12 letras (ej. \"Excelente!\")\n",
    "df_news = df_news[df_news['comment'].str.len() >= 12]\n",
    "df_news = df_news.sample(2000)\n",
    "df_news.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "bflY9AU1Vbh5",
    "outputId": "e02e8a64-4434-4162-f679-59f8b2592513"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2000 entries, 24606 to 52234\n",
      "Data columns (total 6 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   id       2000 non-null   int64  \n",
      " 1   course   2000 non-null   int64  \n",
      " 2   rating   2000 non-null   float64\n",
      " 3   comment  2000 non-null   object \n",
      " 4   user     2000 non-null   object \n",
      " 5   tag      2000 non-null   object \n",
      "dtypes: float64(1), int64(2), object(3)\n",
      "memory usage: 109.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_news.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F6qwR5CAahLp"
   },
   "source": [
    "#Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wbCEhthGasEn"
   },
   "source": [
    "We defined a list of custom words to be exclude from our dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h8EP2Md3FcQr"
   },
   "source": [
    "Create the cleaner function to clean the spanish text, remove non alpha numeric characters, remove duplicate, remove spanish accutes, remove digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Faolin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Faolin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aaaaa']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st = ['aaaaa','asd','asdadsad']\n",
    "y = ['aa','bbb','ccc']\n",
    "[x for x in st if any(string for string in y if string in x)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "stop = set(stopwords.words('spanish'))\n",
    "\n",
    "black_list = ['excelen', 'buen',\n",
    "              'muchas', 'graci'\n",
    "              ]\n",
    "\n",
    "additional_stopwords=set(black_list)\n",
    "\n",
    "stopwords_sp = stop.union(additional_stopwords)\n",
    "\n",
    "from nltk.stem import SnowballStemmer\n",
    "spanish_stemmer = SnowballStemmer('spanish')\n",
    "def stemmization(texts):\n",
    "    texts = re.sub(r\"\"\"\n",
    "                   [,.;@#?!&$]+  # Accept one or more copies of punctuation\n",
    "                   \\ *           # plus zero or more copies of a space,\n",
    "                   \"\"\",\n",
    "                   \" \",          # and replace it with a single space\n",
    "                   texts, flags=re.VERBOSE)\n",
    "    return spanish_stemmer.stem(texts).split()\n",
    "\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('es_core_news_md')\n",
    "def lemmatization(texts, allowed_postags=['NOUN']):\n",
    "    #x = nlp(texts)\n",
    "    #print([(xx.text,xx.pos_) for xx in x])\n",
    "    texts_out = [ token.text for token in nlp(texts) if token.pos_ in \n",
    "                 allowed_postags and token.text not in black_list and len(token.text)>2]\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 646 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bigram = gensim.models.Phrases(df_news['comment'].to_list()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H_7Un4fSFbdC"
   },
   "outputs": [],
   "source": [
    "def cleaner(word):\n",
    "    word = re.sub(r'((http|https)\\:\\/\\/)?[a-zA-Z0-9\\.\\/\\?\\:@\\-_=#]+\\.([a-zA-Z]){2,6}([a-zA-Z0-9\\.\\&\\/\\?\\:@\\-_=#])*', '', word, flags=re.MULTILINE)\n",
    "    word = re.sub(r'(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', \"\", word)\n",
    "    word = re.sub(r'ee.uu', 'eeuu', word)\n",
    "    word = re.sub(r'\\#\\.', '', word)\n",
    "    word = re.sub(r'\\n', '', word)\n",
    "    word = re.sub(r',', ' ', word)\n",
    "    word = re.sub(r'\\-', ' ', word)\n",
    "    word = re.sub(r'\\.{3}', ' ', word)\n",
    "    word = re.sub(r'a{2,}', 'a', word)\n",
    "    word = re.sub(r'é{2,}', 'é', word)\n",
    "    word = re.sub(r'i{2,}', 'i', word)\n",
    "    word = re.sub(r'ja{2,}', 'ja', word) \n",
    "    word = re.sub(r'á', 'a', word)\n",
    "    word = re.sub(r'é', 'e', word)\n",
    "    word = re.sub(r'í', 'i', word)\n",
    "    word = re.sub(r'ó', 'o', word)\n",
    "    word = re.sub(r'ú', 'u', word)  \n",
    "    word = re.sub('[^a-zA-Z]', ' ', word)\n",
    "    wordlist = [ token for token in nltk.word_tokenize(word) if token.lower() not in stopwords_sp and len(token)>3 ]\n",
    "    wordlist = [x for x in wordlist if not any(string for string in black_list if string in x)]\n",
    "    word = \" \".join(wordlist)\n",
    "    list_word_clean = []\n",
    "    for w1 in word.split(r\"\\s\"):\n",
    "        if  w1.lower() not in stopwords_sp:\n",
    "            list_word_clean.append(w1.lower())\n",
    "\n",
    "    bigram_list = bigram[list_word_clean]\n",
    "    out_text = stemmization(\" \".join(bigram_list))\n",
    "    return out_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaner('hola soy un gérmen y tendría pulgas. Pero no,creo que no. O si. excelente! excelente')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vmgAfhN6bWrR"
   },
   "source": [
    "Create the function for select **only nouns** for our data, this way we are removing adverb, adjetives, verbs, etc. This is doing with spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3wMjzGX9bscx"
   },
   "source": [
    "For gensim we need a list of text, so we need do convert the dataframe to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hola',\n",
       " 'soy',\n",
       " 'un',\n",
       " 'germen',\n",
       " 'y',\n",
       " 'tendria',\n",
       " 'pulgas',\n",
       " 'pero',\n",
       " 'no',\n",
       " 'creo',\n",
       " 'que',\n",
       " 'no',\n",
       " 'o',\n",
       " 'si']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmization('hola soy un gérmen y tendría pulgas. Pero no,creo que no. O si')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gérmen', 'pulgas']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatization('hola soy un gérmen y tendría pulgas. Pero no,creo que no. O si')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "IZhWiKxY4Gx2",
    "outputId": "0de89bb9-dc2e-470e-d996-40992ae55e5c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "kJzcwy4ORHD1",
    "outputId": "689b6dc6-ab0a-490d-8700-ac5f1096cb0c"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "colab_type": "code",
    "id": "HciZjXBfwbXM",
    "outputId": "15c4c7c2-a97e-4c33-9922-7922d5410abe"
   },
   "outputs": [],
   "source": [
    "# !python -m spacy download es_core_news_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "yDBAXRQuOnOG",
    "outputId": "a034c4d9-a10d-4db3-a60c-8435eeaa8935"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10053    Hasta el momento me está gustando, la señorita explica muy bien, todo bastante claro y con simpatía...espero aprender mucho con este curso ;)\n",
       "69011                                                                                                                       es una temática innovadora\n",
       "9379                                                                                                                        Interesante hasta el final\n",
       "Name: comment, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news['comment'].sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "2vyiSwQjPCox",
    "outputId": "6577c4eb-29d3-46f8-c5a2-15fbc10576d4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['explicaciones',\n",
       " 'relacion',\n",
       " 'conceptos',\n",
       " 'facil',\n",
       " 'implementar',\n",
       " 'aprender',\n",
       " 'expositor',\n",
       " 'desenvuelve',\n",
       " 'bien',\n",
       " 'videos',\n",
       " 'maneja',\n",
       " 'temas',\n",
       " 'mucha',\n",
       " 'nocion']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaner(df_news['comment'].iloc[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3FqIi24ISgK2"
   },
   "source": [
    "The Cleaner function work properly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yjMX0qS4SmUR"
   },
   "source": [
    "##### Let's clean all the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TBDM5Caomutj"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b831b4f3f04142998f1b758f706f638e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "df_news['comment_cleaned'] = df_news['comment'].progress_apply(cleaner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7egM0YZzRS9r"
   },
   "source": [
    "Now we need to build the *corpus* and the *dictionary* that gensim need to work, to do that we need to pass a list of list of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27469                                                                                                [explicacion, bien, clara, archivos, datos, existen, version, programa, ultima, cambi]\n",
       "62098                                                                                                                                                       [bien, explicado, ideal, inici]\n",
       "6731     [curso, completo, explicado, forma, super, clara, concisa, coach, maravilloso, transmite, mucha, seguridad, honor, haber, formado, parte, curso, muchisimas, julio, abrazo, enorm]\n",
       "13573                                                                                                                                                                  [buena, explicacion]\n",
       "31355                      [curso, instructor, enfoca, detalle, temas, abordados, principiante, python, django, puesto, cambiando, enfoque, profesional, claro, manejo, tema, colaboracion]\n",
       "72951                                                                                    [navegacion, basica, util, informacion, detalles, programa, logra, hacer, desempe, usuario, mejor]\n",
       "21300                                                                                                  [introduccion, bien, supongo, profundizar, conceptos, seria, escoger, cursos, avanz]\n",
       "37394                                                                                 [explicacion, aunque, llevo, algun, tiempo, trabajando, entityframework, entendi, cosas, sabia, haci]\n",
       "12083                                                                                                                                                                      [lento, elinici]\n",
       "53339                                                                                                                  [eleccion, curso, claro, cuenta, material, poder, reafirmar, aprend]\n",
       "Name: comment_cleaned, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news['comment_cleaned'].iloc[200:210]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DZmxTdsYTV35"
   },
   "outputs": [],
   "source": [
    "dictionary = Dictionary(df_news['comment_cleaned'].to_list())\n",
    "dictionary.compactify()\n",
    "# Filter extremes\n",
    "#dictionary.filter_extremes(no_below=5, no_above=0.3)#, keep_n=10000)\n",
    "#dictionary.filter_extremes(no_below=2, no_above=0.97, keep_n=None)\n",
    "dictionary.filter_extremes(no_below=5, no_above=0.2, keep_n=None)\n",
    "dictionary.compactify()\n",
    "\n",
    "corpus = [dictionary.doc2bow(text) for text in df_news['comment_cleaned'].to_list()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NgV46EUdSu0n"
   },
   "source": [
    "# Now let's do the modeling part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GWsxgxE8-YWC"
   },
   "source": [
    "We are comparing 3 topic modeling algorithm Latent Dirichlet Allocation (LDA), Latent\n",
    "semantic analysis (LSA), Hierarchical Dirichlet Process\n",
    "(HDP),in order to evaluate topic models we will be using **topic coherence**, which is a measure of how\n",
    "interpretable topics are for human beings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YwiwW86Man80"
   },
   "source": [
    " ## Hierarchical Dirichlet process Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "opxvCwJcbIs9"
   },
   "outputs": [],
   "source": [
    "hdpmodel = HdpModel(corpus=corpus, id2word=dictionary, random_state= 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KON8iJfmS-f7"
   },
   "source": [
    "and the topics of this model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ewKUhhpgjo8g"
   },
   "outputs": [],
   "source": [
    "def display_topics(model, model_type=\"lda\"):\n",
    "    for topic_idx, topic in enumerate(model.print_topics()):\n",
    "        print (\"Topic %d:\" % (topic_idx))\n",
    "        if model_type== \"hdp\":\n",
    "            print (\" \".join(re.findall( r'\\*(.[^\\*-S]+).?', topic[1])), \"\\n\")\n",
    "        else:\n",
    "            print (\" \".join(re.findall( r'\\\"(.[^\"]+).?', topic[1])), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "-1pogQLHbSl9",
    "outputId": "94002da5-32a7-4c25-b5ac-29b23b8e5959"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "toda  bueno  visto  habia  siendo  lenguaje  clar  entienda  bast  photoshop \n",
      "\n",
      "Topic 1:\n",
      "bien  demas  resultado  iniciarse  deberia  todas  utilidad  temas  basicas  equipo \n",
      "\n",
      "Topic 2:\n",
      "dado  vida  nivel  conten  practicos  aprende  hablando  encuentro  llevo  real \n",
      "\n",
      "Topic 3:\n",
      "ejercicios  expectativas  bases  profesor  necesario  comprar  actividades  algun  proyectos  cantidad \n",
      "\n",
      "Topic 4:\n",
      "empieza  viene  explicar  practicas  recien  pronunciacion  explicacion  final  bi  calificacion \n",
      "\n",
      "Topic 5:\n",
      "ayudado  temas  podria  gratuito  cosas  explicado  actividades  explica  cosa  responde \n",
      "\n",
      "Topic 6:\n",
      "repasar  herramientas  dominio  hice  conocimiento  calidad  mundo  pienso  cero  persona \n",
      "\n",
      "Topic 7:\n",
      "parecido  mala  aplicacion  principiantes  ando  explicando  detallado  recomendable  dado  trabajo \n",
      "\n",
      "Topic 8:\n",
      "primer  varios  ayudan  termine  tipo  encima  practicar  deja  video  cortos \n",
      "\n",
      "Topic 9:\n",
      "dedicacion  conciso  contenido  puesto  aspectos  entender  introduccion  objetivo  concepto  ocasiones \n",
      "\n",
      "Topic 10:\n",
      "leccion  basicas  creacion  recom  proyectos  final  program  siendo  expl  mismo \n",
      "\n",
      "Topic 11:\n",
      "necesitaba  util  perfecto  habia  unas  mismo  concreto  detalles  estudiantes  tips \n",
      "\n",
      "Topic 12:\n",
      "autor  quiero  linux  pract  seguir  bi  alguna  lleva  quede  herramientas \n",
      "\n",
      "Topic 13:\n",
      "desarrollar  poner  empezando  necesitaba  deja  trabaj  atento  clar  peque  parte \n",
      "\n",
      "Topic 14:\n",
      "hizo  didact  recomendado  pronunciacion  concreto  practicar  materiales  trabajo  ideas  aprender \n",
      "\n",
      "Topic 15:\n",
      "informacion  empezando  bootstrap  cosas  aplicar  sirvio  mucha  adquirir  titulo  unas \n",
      "\n",
      "Topic 16:\n",
      "material  practicas  fernando  quiza  perfeccion  final  learning  salud  recomend  recomendable \n",
      "\n",
      "Topic 17:\n",
      "problema  aspectos  youtube  dejar  nunca  entendido  videos  necesito  pude  acerca \n",
      "\n",
      "Topic 18:\n",
      "ahorita  this  conceptos  ejercicios  actualizar  udemy  manejo  idea  encima  marketing \n",
      "\n",
      "Topic 19:\n",
      "instructor  practica  detall  mejor  conocimiento  profesional  entienda  actividades  quizas  falto \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# hdpmodel.show_topics() \n",
    "\n",
    "display_topics(hdpmodel, model_type=\"hdp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jd3LspvVUEXj"
   },
   "source": [
    "as we could see there are 20 topics, however is kind of dificult to interpret or follow, so we decide to move to another model.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4J2IIPqHVTzZ"
   },
   "outputs": [],
   "source": [
    "def evaluate_graph(dictionary, corpus, texts, limit, model):\n",
    "    \"\"\"\n",
    "    Function to display num_topics - LDA graph using c_v coherence\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    limit : topic limit\n",
    "    \n",
    "    Returns:\n",
    "    -------\n",
    "    lm_list : List of LDA topic models\n",
    "    c_v : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    c_v = []\n",
    "    lm_list = []\n",
    "    for num_topics in range(1, limit):\n",
    "        if model == 'lsi':\n",
    "            lm = LsiModel(corpus=corpus, num_topics=num_topics, id2word=dictionary)\n",
    "        else:\n",
    "            lm = LdaModel(corpus=corpus, num_topics=num_topics, id2word=dictionary)\n",
    "        lm_list.append(lm)\n",
    "        cm = CoherenceModel(model=lm, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        c_v.append(cm.get_coherence())\n",
    "        \n",
    "    # Show graph\n",
    "    x = range(1, limit)\n",
    "    plt.plot(x, c_v)\n",
    "    plt.xlabel(\"num_topics\")\n",
    "    plt.ylabel(\"Coherence score\")\n",
    "    plt.legend((\"c_v\"), loc='best')\n",
    "    plt.show()\n",
    "    \n",
    "    return lm_list, c_v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hse2o99bZ8wi"
   },
   "source": [
    "##LSI MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HFQCfc9VcmT7"
   },
   "outputs": [],
   "source": [
    "lsimodel = LsiModel(corpus=corpus, num_topics=10, id2word=dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "colab_type": "code",
    "id": "yfrJmKuLaUrg",
    "outputId": "b7add73d-8ca9-41fb-b93f-eb4de56773dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "bien explicado explica explic excelente profesor facil instructor curs temas \n",
      "\n",
      "Topic 1:\n",
      "bien excelente curs explic explicacion instructor temas explicado explica manera \n",
      "\n",
      "Topic 2:\n",
      "excelente curs explica temas profesor solo bien hace explic videos \n",
      "\n",
      "Topic 3:\n",
      "explicacion curs facil explica clara entender profesor explicado manera tema \n",
      "\n",
      "Topic 4:\n",
      "temas explica curs profesor solo visto tema informacion explicado explicacion \n",
      "\n",
      "Topic 5:\n",
      "facil explica manera informacion curs explicado entender explic explicacion herramientas \n",
      "\n",
      "Topic 6:\n",
      "curs excelente explica temas informacion solo explicacion instructor parte explicado \n",
      "\n",
      "Topic 7:\n",
      "explicacion informacion profesor eleccion facil gran curs explica entender conceptos \n",
      "\n",
      "Topic 8:\n",
      "claro eleccion momento curs explicado parte temas excelente instructor paso \n",
      "\n",
      "Topic 9:\n",
      "informacion explica claro bastante eleccion explicado cosas curs ense clara \n",
      "\n"
     ]
    }
   ],
   "source": [
    "display_topics(lsimodel)  # Showing the topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t-Bt22W-r1ZO"
   },
   "source": [
    "It seen that with 10 topics there is some themes with keywords related to: trump, venezuela, police, electiones, terrorism; still is a little difficult to gt some insight, because of this we are trying to select the best number of topics by iterate over a range of values and looking the coherence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 318
    },
    "colab_type": "code",
    "id": "dtXS4IfIVYIJ",
    "outputId": "916f153b-dc7d-4484-8a62-b9be3a788328"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "lmlist_lsi, c_v = evaluate_graph(dictionary=dictionary, corpus=corpus, texts=df_news['comment_cleaned'].to_list(), limit=21, model= \"lsi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kmzyPFWiw63V"
   },
   "source": [
    "According to the coherence the best number of topics are between 3-7, however you must select the topics using both the coherence and visual inspection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "TczLrG1ZRL4_",
    "outputId": "97713743-960a-4570-b917-63cd2437b058"
   },
   "outputs": [],
   "source": [
    "display_topics(lmlist_lsi[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v6ty9sFNyRyG"
   },
   "source": [
    "Now, Let's try another model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "earp2d28dz3a"
   },
   "source": [
    "## Latent Dirichlet Allocation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wiI55UzIdnUN"
   },
   "outputs": [],
   "source": [
    "ldamodel = LdaModel(corpus=corpus, num_topics=10, id2word=dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "colab_type": "code",
    "id": "fjAbhPAMd7_B",
    "outputId": "6128b18b-dcda-4960-8e98-ab2fa440b5de"
   },
   "outputs": [],
   "source": [
    "display_topics(ldamodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2cywaW1QsJ8N"
   },
   "source": [
    "Find out the optimal number of topics for the LDA model based on the coherence metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 318
    },
    "colab_type": "code",
    "id": "Rd651y6mWpTF",
    "outputId": "18376c3d-d18a-465e-d115-9b2b55c02005"
   },
   "outputs": [],
   "source": [
    "%%timer\n",
    "lmlist, c_v = evaluate_graph(dictionary=dictionary, corpus=corpus, texts=df_news['comment_cleaned'].to_list(), limit=21, model= \"lda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P0T4UJGmyiLp"
   },
   "source": [
    "For this model it seems that  9 or 18, again we must to check the keywords too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S6S88TE0eslU"
   },
   "source": [
    "### Comparing the Model Coherence of the Best Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6dnp010Wz6Xo"
   },
   "source": [
    "we made 3 models, now let's compare each other's  coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s0bosG67ev6L"
   },
   "outputs": [],
   "source": [
    "ldamodel = lmlist[11]\n",
    "lsimodel = lmlist_lsi[2]\n",
    "\n",
    "lsitopics = [[word for word, prob in topic] for topicid, topic in lsimodel.show_topics(formatted=False)]\n",
    "\n",
    "hdptopics = [[word for word, prob in topic] for topicid, topic in hdpmodel.show_topics(formatted=False)]\n",
    "\n",
    "ldatopics = [[word for word, prob in topic] for topicid, topic in ldamodel.show_topics(formatted=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IP5GpYG1e4nT"
   },
   "outputs": [],
   "source": [
    "lsi_coherence = CoherenceModel(topics=lsitopics[:10], texts=df_news['comment_cleaned'].to_list(), dictionary=dictionary, window_size=10).get_coherence()\n",
    "\n",
    "hdp_coherence = CoherenceModel(topics=hdptopics[:10], texts=df_news['comment_cleaned'].to_list(), dictionary=dictionary, window_size=10).get_coherence()\n",
    "\n",
    "lda_coherence = CoherenceModel(topics=ldatopics, texts=df_news['comment_cleaned'].to_list(), dictionary=dictionary, window_size=10).get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "colab_type": "code",
    "id": "XntcwwKufZTp",
    "outputId": "7278380a-d093-4908-a44a-0ba94a2d7aac"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "coherences = [lsi_coherence, hdp_coherence, lda_coherence]\n",
    "n = len(coherences)\n",
    "x = ['lsi_coherence','hdp_coherence', 'lda_coherence']\n",
    "sns.barplot(x, coherences)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bXKu-wAoFMRY"
   },
   "source": [
    "We can see that the **LdaModel** model **with 8 topics** has the higher value of\n",
    "coherence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B5Ii_TedVNHq"
   },
   "source": [
    "Examine the keyword to get the topics of the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 629
    },
    "colab_type": "code",
    "id": "qtOtsGxHuD8W",
    "outputId": "841b40c9-401d-4e5e-a6bc-cf6e1d7a7169"
   },
   "outputs": [],
   "source": [
    "\n",
    "display_topics(ldamodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "23tYxCUIchga"
   },
   "source": [
    "It looks like the topics are:\n",
    "* Topic 0: felicitaciones\n",
    "* Topic 1: expectativas\n",
    "* Topic 2: experiencia\n",
    "* Topic 3: contenido\n",
    "* Topic 4: instructor\n",
    "* Topic 5: material\n",
    "* Topic 6: video\n",
    "* Topic 7: lenguaje\n",
    "* Topic 8: ejercicios\n",
    "* Topic 9: titulo\n",
    "* Topic 10: temas\n",
    "* Topic 11: explicación\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dicc = {0:'felicitaciones', 1:'expectativas', 2:'experiencia', 3: 'contenido', 4:'instructor', 5:'material', 6:'video', \n",
    "              7:'lenguaje', 8:'ejercicios', 9: 'titulo', 10:'temas', 11:'explicación'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v0aL-yqAFzUS"
   },
   "source": [
    "Let´s check the keyword when we selecting another number of topics (14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AGXxaEtVudnc"
   },
   "outputs": [],
   "source": [
    "ldamodel_16 =lmlist[16]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 680
    },
    "colab_type": "code",
    "id": "aS3QJ5KV5z_c",
    "outputId": "1d87fea1-bfa5-476a-e472-a7e585bd8cf3"
   },
   "outputs": [],
   "source": [
    "display_topics(ldamodel_16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u2clSiIF1yHy"
   },
   "source": [
    "# Classifiying all documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_sLVX03-1_GB"
   },
   "source": [
    "now that we have been select the best model and topics number, is time to assign a topic to each document, means **cluster** according to the topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9fojFPHKW204"
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm_notebook\n",
    "\n",
    "def format_topics_sentences(ldamodel=0, corpus=corpus, texts=0):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()-n\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row in tqdm_notebook(enumerate(ldamodel[corpus]), total=len(ldamodel[corpus])):\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)\n",
    "\n",
    "\n",
    "df_topic_sents_keywords = format_topics_sentences(ldamodel, corpus=corpus, texts=df_news['comment_cleaned'].to_list())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "id": "E8FofLvzYmTP",
    "outputId": "1f5226b4-02cf-4243-e7a1-ab89ddb707b5"
   },
   "outputs": [],
   "source": [
    "# Format\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "\n",
    "# Show\n",
    "df_dominant_topic.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9vtBDBQKkzmK"
   },
   "source": [
    "We selected the ldamodel with 12 topics and asigned a dominant topic to each document, now let map each topic with a label "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z8f8u5UJlQJ8"
   },
   "source": [
    "first let's create the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I27y-Pd-lXL8"
   },
   "outputs": [],
   "source": [
    "label_dicc = {0:'felicitaciones', 1:'expectativas', 2:'experiencia', 3: 'contenido', 4:'instructor', 5:'material', 6:'video', \n",
    "              7:'lenguaje', 8:'ejercicios', 9: 'titulo', 10:'temas', 11:'explicación'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qUspHFcPopTz"
   },
   "outputs": [],
   "source": [
    "df_dominant_topic['Dominant_Topic'] = df_dominant_topic['Dominant_Topic'].astype('int64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "id": "o9XM5yHgnmg5",
    "outputId": "1d89e87e-a9e1-401e-edd1-63457a7f50c4"
   },
   "outputs": [],
   "source": [
    "df_dominant_topic['Dominant_Topic'] = df_dominant_topic['Dominant_Topic'].map(label_dicc)\n",
    "df_dominant_topic.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "in5E52W3pl_k"
   },
   "outputs": [],
   "source": [
    "df_news['labels'] = df_dominant_topic['Dominant_Topic']\n",
    "df_news['label_confidence'] = df_dominant_topic['Topic_Perc_Contrib']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mA35orWWqQMt"
   },
   "source": [
    "Let's examine some text and its topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 335
    },
    "colab_type": "code",
    "id": "7cHF6NEHkHYh",
    "outputId": "8141df9c-6d26-4d3d-d6d9-9643da78a7c7"
   },
   "outputs": [],
   "source": [
    "df_news[['comment', 'labels']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 115
    },
    "colab_type": "code",
    "id": "sgkBFTYbqID0",
    "outputId": "cb7ce341-6c49-48c3-eb15-cccb8a5ea902"
   },
   "outputs": [],
   "source": [
    "df_news[ df_news['labels'] == 'instructor'].sort_values(by='label_confidence',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_news.sort_values(by='label_confidence',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dCc6-oIo6BMw"
   },
   "source": [
    "### let's see the distribution of topics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "colab_type": "code",
    "id": "VOitT-s10yv5",
    "outputId": "16a4b62a-dd36-4607-a55b-ad77f80acf65"
   },
   "outputs": [],
   "source": [
    "ax = df_dominant_topic['Dominant_Topic'].value_counts().plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jh0l7ngJ6J12"
   },
   "source": [
    "The topis are almost balanced, so we are good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AcWRIAWTWhl7"
   },
   "source": [
    "finally that we have our models set up, as well as analyzed, we can go\n",
    "ahead to visualizing them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 521
    },
    "colab_type": "code",
    "id": "Jv3PFRwBs-gT",
    "outputId": "6749bc00-2549-4857-d0bd-df8540c8accd"
   },
   "outputs": [],
   "source": [
    "!pip install pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jXpx66NTd1uT"
   },
   "outputs": [],
   "source": [
    "import pyLDAvis\n",
    "\n",
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 991
    },
    "colab_type": "code",
    "id": "diu2MLik41sf",
    "outputId": "078af8ba-2310-4875-c8de-e24a06ee6340"
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "import pyLDAvis.gensim\n",
    "pyLDAvis.gensim.prepare(ldamodel, corpus, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "topic_modeling_spanish.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
